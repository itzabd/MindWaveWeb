{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:36:26.634457Z",
     "start_time": "2025-04-30T10:36:26.566673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Additional filtering is not required as the data is already preprocessed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_eeg_data(file_path):\n",
    "    \"\"\"\n",
    "    Load EEG data from a csv file and separate data and label.\n",
    "    :param file_path: File path of the EEG data\n",
    "    :return: EEG data (DataFrame), label\n",
    "    \"\"\"\n",
    "    data_src = pd.read_csv(file_path)\n",
    "    data = data_src.iloc[:, :-1]  # Exclude the last column as it is a label\n",
    "    label = data_src.iloc[:, -1]  # Use the last column as a label\n",
    "    return data, label\n",
    "\n",
    "\n",
    "def compute_band_power(raw, band):\n",
    "    \"\"\"\n",
    "    Compute the power in a specific frequency band.\n",
    "    :param raw: MNE Raw object\n",
    "    :param band: Frequency band of interest (tuple)\n",
    "    :return: Power in the frequency band\n",
    "    \"\"\"\n",
    "    fmin, fmax = band  # Setting frequency band\n",
    "    data = raw.get_data()\n",
    "    sfreq = raw.info['sfreq']\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(data, sfreq=sfreq, fmin=fmin, fmax=fmax, n_fft=128)  # Compute PSD\n",
    "    # Compute power in the frequency band\n",
    "    band_power = np.sum(psds, axis=-1)\n",
    "    return band_power\n",
    "\n",
    "\n",
    "def extract_features(data, selected_columns, sfreq=250):\n",
    "    \"\"\"\n",
    "    Extract features from EEG data. Furthermore, the data is downsampled to the target sampling frequency.\n",
    "    :param data: EEG data (DataFrame)\n",
    "    :param selected_columns: List of tuples containing channel index and frequency bands\n",
    "    :param sfreq: Sampling frequency of the data\n",
    "    :param target_sfreq: Target sampling frequency\n",
    "    :return: Extracted features (DataFrame)\n",
    "    \"\"\"\n",
    "    feature_dict = {}  # 결과를 저장할 딕셔너리\n",
    "\n",
    "    for item in selected_columns:\n",
    "        channel_idx = item[0]  # 채널 인덱스\n",
    "        bands = item[1]  # 해당 채널에서 추출할 주파수 대역 리스트\n",
    "\n",
    "        # 주파수 대역이 하나만 주어졌을 때도 리스트로 처리\n",
    "        if isinstance(bands, tuple):\n",
    "            bands = [bands]\n",
    "\n",
    "        # 채널의 데이터 추출\n",
    "        eeg_data = data.iloc[:, channel_idx].values  # 특정 채널의 데이터를 가져옴\n",
    "        ch_name = data.columns[channel_idx]  # 채널 이름\n",
    "\n",
    "        # mne RawArray 객체 생성\n",
    "        info = mne.create_info(ch_names=[ch_name], sfreq=sfreq, ch_types='eeg')\n",
    "        raw = mne.io.RawArray(eeg_data[np.newaxis, :], info)  # 2D array 필요\n",
    "\n",
    "        # 주파수 대역별로 PSD 계산\n",
    "        for band in bands:\n",
    "            band_power = compute_band_power(raw, band)\n",
    "            # 열 이름 생성 (예: Channel_1_10-12Hz)\n",
    "            column_name = f'{ch_name}_{band[0]}-{band[1]}Hz'\n",
    "            feature_dict[column_name] = band_power\n",
    "\n",
    "    # 최종 데이터프레임 생성\n",
    "    features = pd.DataFrame([feature_dict])\n",
    "\n",
    "    return features\n"
   ],
   "id": "fb078dcdf8c7cd63",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_path = 'your_path/'\n",
    "\n",
    "train_csv_path = \"laf_eeg_data_9ch_360000_train.csv\"\n",
    "val_csv_path = \"laf_eeg_data_9ch_360000_val.csv\"\n",
    "test_csv_path = \"laf_eeg_data_9ch_360000_test.csv\"\n",
    "\n",
    "train_json_path = base_path + 'json/l1b_train.json'\n",
    "train_jsonl_path = base_path + 'jsonl/l1b_train.jsonl'\n",
    "\n",
    "val_json_path = base_path + 'json/l1b_val.json'\n",
    "val_jsonl_path = base_path + 'jsonl/l1b_val.jsonl'\n",
    "\n",
    "# csp_train_path = base_path + 'csp1/class_1_vs_5_train_features.csv'\n",
    "# csp_val_path = base_path + 'csp1/class_1_vs_5_val_features.csv'\n",
    "# csp_test_path = base_path + 'csp1/class_1_vs_5_test_features.csv'\n",
    "csp_train_path = 'class_1_vs_5_train_features.csv'\n",
    "csp_val_path = 'class_1_vs_5_val_features.csv'\n",
    "csp_test_path = 'class_1_vs_5_test_features.csv'"
   ],
   "id": "3a791e7b4da020a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from feature_extraction import *\n",
    "dftrain, labeltrain = load_eeg_data(train_csv_path)\n",
    "dfval, labelval = load_eeg_data(val_csv_path)\n",
    "dftest, labeltest = load_eeg_data(test_csv_path)\n",
    "print(dftrain.shape)\n",
    "print(labeltrain.shape)"
   ],
   "id": "7f76a36bcd4bf07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T11:30:31.485454Z",
     "start_time": "2025-04-30T11:30:30.201360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "csptrain, csptrainlabel = load_eeg_data(csp_train_path)\n",
    "csptrain = csptrain.to_numpy()\n",
    "cspval, cspvallabel = load_eeg_data(csp_val_path)\n",
    "cspval = cspval.to_numpy()\n",
    "csptest, csptestlabel = load_eeg_data(csp_test_path)\n",
    "csptest = csptest.to_numpy()"
   ],
   "id": "bf91e4f4988791b4",
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mEmptyDataError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m csptrain, csptrainlabel = \u001B[43mload_eeg_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsp_train_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m csptrain = csptrain.to_numpy()\n\u001B[32m      3\u001B[39m cspval, cspvallabel = load_eeg_data(csp_val_path)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MindWaveWeb\\feature_extraction.py:16\u001B[39m, in \u001B[36mload_eeg_data\u001B[39m\u001B[34m(file_path)\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_eeg_data\u001B[39m(file_path):\n\u001B[32m     11\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[33;03m    Load EEG data from a csv file and separate data and label.\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[33;03m    :param file_path: File path of the EEG data\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[33;03m    :return: EEG data (DataFrame), label\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m     data_src = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m     data = data_src.iloc[:, :-\u001B[32m1\u001B[39m]  \u001B[38;5;66;03m# Exclude the last column as it is a label\u001B[39;00m\n\u001B[32m     18\u001B[39m     label = data_src.iloc[:, -\u001B[32m1\u001B[39m]  \u001B[38;5;66;03m# Use the last column as a label\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MindWaveWeb\\.venv2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MindWaveWeb\\.venv2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MindWaveWeb\\.venv2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MindWaveWeb\\.venv2\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1895\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[32m   1897\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1898\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1899\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1900\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\MindWaveWeb\\.venv2\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001B[39m, in \u001B[36mCParserWrapper.__init__\u001B[39m\u001B[34m(self, src, **kwds)\u001B[39m\n\u001B[32m     90\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwds[\u001B[33m\"\u001B[39m\u001B[33mdtype_backend\u001B[39m\u001B[33m\"\u001B[39m] == \u001B[33m\"\u001B[39m\u001B[33mpyarrow\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     91\u001B[39m     \u001B[38;5;66;03m# Fail here loudly instead of in cython after reading\u001B[39;00m\n\u001B[32m     92\u001B[39m     import_optional_dependency(\u001B[33m\"\u001B[39m\u001B[33mpyarrow\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m \u001B[38;5;28mself\u001B[39m._reader = \u001B[43mparsers\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTextReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     95\u001B[39m \u001B[38;5;28mself\u001B[39m.unnamed_cols = \u001B[38;5;28mself\u001B[39m._reader.unnamed_cols\n\u001B[32m     97\u001B[39m \u001B[38;5;66;03m# error: Cannot determine type of 'names'\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mparsers.pyx:581\u001B[39m, in \u001B[36mpandas._libs.parsers.TextReader.__cinit__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mEmptyDataError\u001B[39m: No columns to parse from file"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "selected_columns = [\n",
    "        [0, [(10, 12), (12, 14)]],  # FCz\n",
    "        [2, [(20, 22), (22, 24)]],  # C3\n",
    "        [3, [(8, 10)]],  # Cz\n",
    "        [4, [(20, 22), (22, 24)]],  # C4\n",
    "        [5, [(28, 30)]],  # CP3\n",
    "]"
   ],
   "id": "e476b72f55ee3e43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def csv_to_df(df, csp, window_size, selected_columns, labels):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame of EEG data into a JSON format suitable for GPT-3 davinci.\n",
    "    :param df: Data converted to pandas DataFrame from the original csv file\n",
    "    :param window_size: Window size to divide EEG data\n",
    "    :param selected_columns: EEG channel to use (provide a list with frequency bands)\n",
    "    :param labels: Label for each window (provide a list, left, right, top, bottom)\n",
    "    :return: List of data in JSON format\n",
    "    \"\"\"\n",
    "    df_array = pd.DataFrame()\n",
    "\n",
    "    # EEG 채널 이름을 selected_columns에 매핑합니다.\n",
    "    channel_names = ['FCz', 'C3', 'Cz', 'C4', 'CP3']  # 각각 0, 1, 2, 3에 대응\n",
    "\n",
    "    for start in range(0, len(df) - window_size + 1, window_size):\n",
    "        window_data = df.iloc[start:start + window_size, :]  # 전체 데이터를 가져옴\n",
    "        label = str(int(labels[start]))  # Assuming labels are provided for each window\n",
    "\n",
    "        # Extract features using the updated extract_features function\n",
    "        features = extract_features(window_data, selected_columns)  # feature extraction\n",
    "        cspdata = pd.DataFrame(csp[int(start / 1000)]).T  # cspdata 가져옴\n",
    "        # features와 cspdata 가로 방향으로 합침\n",
    "        features = pd.concat([features, cspdata], axis=1)\n",
    "        # 라벨까지 합치기, 라벨의 column명은 'Label'\n",
    "        features['Label'] = label\n",
    "        \n",
    "        # 최종 데이터프레임 생성\n",
    "        df_array = pd.concat([df_array, features], axis=0)\n",
    "    return df_array"
   ],
   "id": "71a58713f11c071f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train4ml = csv_to_df(dftrain, csptrain, 1000, selected_columns, labeltrain)\n",
    "train4ml"
   ],
   "id": "30741f09082069ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val4ml = csv_to_df(dfval, cspval, 1000, selected_columns, labelval)\n",
    "val4ml"
   ],
   "id": "6e845a866e0ffef1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test4ml = csv_to_df(dftest, csptest, 1000, selected_columns, labeltest)\n",
    "test4ml"
   ],
   "id": "5accbb17e0939b5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train4ml.to_csv(base_path+'train4ml.csv')\n",
    "val4ml.to_csv(base_path+'val4ml.csv')\n",
    "test4ml.to_csv(base_path+'test4ml.csv')"
   ],
   "id": "fee9107fdd315586"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d963771a3edc76aa"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
