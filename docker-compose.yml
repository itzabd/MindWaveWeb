version: '3.8'

services:
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      FLASK_APP: app.py
      FLASK_ENV: development
      SUPABASE_URL: "your-supabase-url"
      SUPABASE_KEY: "your-anon-key"
      LOCALAI_URL: "http://localai:8080"
      EEG_MODEL_NAME: "eeg-classifier"
      SECRET_KEY: "your-secret-key"
    volumes:
      - .:/app
      - ./eeg_data:/app/eeg_data
    depends_on:
      - localai
      - redis  # Add Redis for caching if needed

  localai:
    image: localai/localai:latest-cpu
    ports:
      - "8080:8080"
    volumes:
      - ./models:/models
      - ./eeg_model:/eeg_model  # Directory for your EEG model
    environment:
      - MODELS_PATH=/models
      - PRELOAD_MODELS=/models/eeg-classifier.yaml
      - DEBUG=true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:  # Optional for caching
    image: redis:alpine
    ports:
      - "6379:6379"